{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "#### Overview\n",
    "In vanilla CNN the size of the input and output is fixed. As for example for a fixed length and width of an image there is a class value for that image. But in practical life often we need to work with variably length of inputs and outputs. Here comes RNN to play a crucial role. RNN is like a black box where it takes input vectors and previous hidden state and updates its hidden state by computing these two values. Let's say, $h_0$ is the initial hidden state of a hidden layer of RNN, $x_t$ is input. then RNN calculates these two terms and updates its hidden state. In this manner the hidden state in a certain time step serves as the input of the next time step. This is why this is called Recurrent Neural Network.\n",
    "Here is the equation we can summarize, $h_t=fW(h_{tâˆ’1},xt)$. We can say that this is a same function with the same weight matrix W.\n",
    "\n",
    "![alt text](images/1.PNG \"RNN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the most simplest RNN( vanilla RNN) we can have just one hidden layer which corresponds to only one hidden state. We will update the hidden state by applying the above same function. Let's say, previous hidden state is $h_{t-1}$ and current input is $x_t$ at any time state t. We will have two weight metrics for these two inputs.\n",
    "- $W_{hh}$ hideen to hidden weight matrix\n",
    "- $W_{xh}$ input to hidden weight matrix\n",
    "we will finally update hidden state at any time step t as follows,\n",
    "$h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t)$\n",
    "![alt text](images/2.PNG)\n",
    "\n",
    "we can also predict output for each time step by projecting another matrix on top of the hidden state. $y_t = W_{hy}h_t$  \n",
    "![alt text](images/3.PNG)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graph\n",
    "![alt text](images/cg1.PNG) ![alt text](images/cg2.PNG) \n",
    "![alt text](images/cg3.PNG) ![alt text](images/cg4.PNG)\n",
    "![alt text](images/cg5.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of RNN\n",
    "- one to one: vanilla RNN. Input and output is of fixed size.\n",
    "- one to many: Image Captioning\n",
    "- many to one: \n",
    "  - Action prediction from a sequence of video frames instead of a single image.\n",
    "  - sentiment analysis (NLP)\n",
    "- many to many:\n",
    "  - Video Captioning: from a sequence of video frames output is a caption describing the videos.\n",
    "  -  machine translation: from a text in a particular language to another language.\n",
    "  - video classification: on a frame level. the model generates an output at each time step.\n",
    "\n",
    "![alt text](images/4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RNN advantages**:\n",
    " - Can Process any length of input\n",
    " - Computation for step t can (in theory) use information from many steps back\n",
    " - Model size doesn't increase for longer inputs\n",
    " - Same weights applied on every timestep, so there is symmetry in how inputs are processed\n",
    "\n",
    "- **RNN Disadvantages**:\n",
    " - Recurrent computation is slow\n",
    " - In practice, difficult to access information from many steps back"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
