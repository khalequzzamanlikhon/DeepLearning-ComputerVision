{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In classification problem we have an input image and our task is to label that image only. But sometimes we might want to know the label of the image as well as the location. This prroblem is known as classification and locaalizatioon. For example in our example the cat is on a field. Our task is to label the image as cat and the location as field. We already know the classifcation process. Here, localization refers to the bounding box of the object (in our example bounding box around the cat).\n",
    "\n",
    "The differences between object detection and \"classification and localization\" is that in the former problem we may have multiple object but in latter case there is only one object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure\n",
    "\n",
    "We take our input image and pass it through a giant convolutional neural network(in our example: Alex Net) which will summarize the input image into a vector. Now unlike classification problem, we will feed this vector into two separate fully connceted layers instead of one. One will give class scores and the other will give four numbers height, width and the coordinates of the bounding box x and y. \n",
    "\n",
    "Now we will have two losses for this two different outputs. Moreover, we do this task in a fully supervised way. We assume that each of out training images are annoted with both a category label and also a ground truth bounding box for that category in the image. So, now we have two loss functions as well. One is famous softmax loss and the other is simply L2 loss. We might take other loss functions for the second case like L1, smooth L1 etc..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/cl1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two scalars for gradient computing and we want to minimize both. To do so we will take another hyperparameters that gives us some weights. Now we will take wighted sum of these loss functions to give our final scalar loss. Then we will take gradients w.r.t. this new scalar.\n",
    "\n",
    "This is also tricky because, this additional hyperparameter is to be set. We can different set of this hyperparameter and observe which performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proess of classification and localization can be applied to human pose estimation. In this case, the input is an image of a person and we want to output the positions of the joints for that person. This will allow the network to prdict where the his arms were, where his legs were staff like that.\n",
    "\n",
    "We assume every person has same number of joints naturally. However it might not be the case all the time, but it works for the network. Generally the datasets for this problem defines a person's pose by 14 joint positions, their feet, knees, their hips etc. Therefore our task will be to output 14 numbers giving the (x,y) co-ordinates for each of the joints. We will apply regression loss(other than softmax and cross entropy loss) on each of those 14 predicted points and train the network with back propagation again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/cl2.PNG) ![alt text](images/cl3.PNG) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
